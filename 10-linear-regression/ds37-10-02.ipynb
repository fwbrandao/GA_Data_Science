{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Objectives\n",
    "*By the end of this notebook, you will be able to:*\n",
    "- Define data modeling and simple linear regression.\n",
    "- Build a linear regression model using a data set that meets the linearity assumption using the scikit-learn library.\n",
    "- Understand and identify multicollinearity in a multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "\n",
    "# <font color='blue'> What is linear regression?\n",
    "\n",
    "\n",
    "Linear regression is a way of modelling some depdendent variable $y$ as a linear combination of one or more independent variables $x$.\n",
    "\n",
    "We are often taught the formula for a straight line is: $y = mx + b$.\n",
    "\n",
    "This can alternatively be written as: $$y = \\beta_{0} + \\beta_{1} x$$\n",
    "\n",
    "## What are the independent and dependent variables in this formula?\n",
    "\n",
    "In regression tasks, the **dependent** variable is continuous. In classification tasks, the **dependent** variable is categorical. \n",
    "\n",
    "An example of a regression problem could be: Predicting Google's share price.\n",
    "An example of a classification task could be: Predicting a person's favourite fruit.\n",
    "\n",
    "It's important to note that features in both classification and regression tasks can be a combination of continuous and categorical (we often need to transform categorical features into continuous ones or vice versa depending on the type of model we're using). \n",
    "\n",
    "## What do we mean by linear?\n",
    "\n",
    "An equation is **linear** if the highest degree of any of the the independent variables (i.e. $x$) is 1. If there's a term containing $x^2$ for example, the equation is no longer linear because the independent variable is being raised to a power higher than 1. \n",
    "\n",
    "\n",
    "## What does 'training' or 'fitting' a linear regression model mean?\n",
    "\n",
    "Linear regression is our first example of supervised learning. In supervised learning tasks, we:\n",
    "\n",
    "1. Obtain a dataset that consists of lots of data points, where each point consists of:\n",
    "\n",
    "    * A value for our label/response/target/dependent variable $y$\n",
    "    * Corresponding values for our features/predictors/independent variables $x$\n",
    "    \n",
    "    You can think of a single 'data point' or 'observation' as corresponding to a single row in a Pandas dataframe\n",
    "    \n",
    "2. Split the dataset into a training set that we'll use to fit or train our model, and a testing set that we'll use to evaluate our model's accuracy. A typical split is 80% of our data will be used for training, and 20% for testing. \n",
    "\n",
    "3. Train or fit our model. This will be different for different models. \n",
    "\n",
    "In linear regression, training is the process of finding the linear equation that best fits our data.\n",
    "\n",
    "In other words, we're finding the $\\beta$ values or **model coefficients** that give us the line of best fit:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are trying to find the line (mathematically) that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- Once we've learned these coefficients, we can use the model to predict the values for $y$, the dependent variable (or 'response') for new data points where we only have access to $x$, the features.\n",
    "\n",
    "![Estimating coefficients](./assets/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line.\n",
    "\n",
    "Evaluation metrics for classification problems, such as accuracy, are not useful for regression problems. We need evaluation metrics designed for comparing continuous values.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean squared error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "Let's compare these metrics:\n",
    "\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world. Also, MSE is continuous and differentiable, making it easier to use than MAE for optimization.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "## Why use linear regression?\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain.\n",
    "- Highly interpretable.\n",
    "- Model training and prediction are fast.\n",
    "- No tuning is required (excluding regularization).\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "- Well understood.\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias.\n",
    "- Can't automatically learn feature interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "\n",
    "# <font color='blue'> Simple linear regression\n",
    "\n",
    "Let's work through a simple example with dummy data to understand how linear regression works. \n",
    "\n",
    "Imagine we have a data frame that describes the vote share of the X Party vs the percentage of 18-25 year olds in a particular constituency. (Note: this is dummy data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression # import\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df = pd.DataFrame({'vote_share':[44, 20, 67, 12, 80, 20, 80, 76, 34, 11],\n",
    "                         'young_population':[24, 8, 28, 7, 35, 14, 40, 39, 29, 8]})\n",
    "votes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "\n",
    "Split our data 80/20 into a training and a testing set. **Use random state 42**\n",
    "\n",
    "We'll train the model on the training set, and test how well it generalises on the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(votes_df['young_population']).reshape(-1,1) # features\n",
    "y = # fill in \n",
    "\n",
    "X_train, X_test, y_train, y_test = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use scikit-learn to fit our model and make predictions\n",
    "\n",
    "This bit is super simple with scikit-learn! We import scikit-learn, initialise the linear regression model, and then fit it to our data:\n",
    "\n",
    "**Step 1:** Import the class you plan to use from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Initialise the model\n",
    "\n",
    "* We've created an object that \"knows\" how to do linear regression, and is just waiting for data.\n",
    "* The ame of the object does not matter.\n",
    "* All parameters not specified are set to their defaults.\n",
    "* We can specify tuning parameters (aka \"hyperparameters\") during this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression() # initialise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\").\n",
    "\n",
    "- Model is \"learning\" the relationship between X and y in our \"training data.\"\n",
    "- Process through which learning occurs varies by model.\n",
    "- Occurs in-place.\n",
    "\n",
    "Note that 'X' and 'y' correspond to the correct columns in our 'votes' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train) # fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! `linreg` is now a trained model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Inspect our trained model.\n",
    "\n",
    "Now we've fitted our linear regression model, we can look at the coefficients it's learned and evaluate how well the model fits our data using the **sum of squared errors** metric we defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = linreg.coef_\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = linreg.intercept_\n",
    "print(intercept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what the learned coefficient and intercept of our model is, let's write down a formula describing the learned relationship between vote share and young population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the values of the line of best fit for our training set using `.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the line of best fit against our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train)\n",
    "plt.plot(X,y_model,'r',linewidth=0.5)\n",
    "plt.scatter(X_test,y_test)\n",
    "plt.xlabel('Percentage of people aged 18-25')\n",
    "plt.ylabel('Party vote share')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the intercept ($\\beta_0$):\n",
    "\n",
    "- It is the value of $y$ when all independent variables are 0.\n",
    "- Here, it is the estimated vote share when there are no 18-25 year olds in a constituency.\n",
    "- **Note:** It does not always make sense to interpret the intercept; why? \n",
    "\n",
    "Interpreting the \"youth\" coefficient ($\\beta_1$):\n",
    "\n",
    "- **Interpretation:** An increase of 1% in youth population in a constituency is _associated with_ increasing the Party vote share by $\\beta_1$\n",
    "- In this case, an increase of 1% in youth population in a constituency is _associated with_ increasing the Party vote share by 2.3%\n",
    "- This is not a statement of causation.\n",
    "- $\\beta_1$ would be **negative** if an increase in youth population was associated with a **decrease** in Party vote share.\n",
    "- $\\beta_1$ would be **zero** if youth population is not at all associated with Party vote share."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Evaluate our model\n",
    "\n",
    "Exactly how well does our formula, or our 'line of best fit' fit our data?\n",
    "\n",
    "We can calculate the **mean squared error** and **root mean squared error** using scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_train, linreg.predict(X_train))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared TRAINING error: %f'% mse)\n",
    "print('Root mean squared TRAINING error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the **R squared coefficient for our training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's not enough to know how well our model fits our training data; this is useless information if the model doesn't perform well on 'unseen', out of sample data from our testing set!\n",
    "\n",
    "Now we find our testing accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, linreg.predict(X_test))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared TESTING error: %f'% mse)\n",
    "print('Root mean squared TESTING error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the RMSE as meaning that **on average, the model will get the party's vote share wrong by around 18 percentage points whenever it makes a prediction.**\n",
    "\n",
    "Is this good? \n",
    "\n",
    "We can compare our model to a null model, or a baseline. \n",
    "\n",
    "In regression tasks, it's common for the baseline model to be **a model that always predicts the mean value of the dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_model = np.mean(y_train)*np.ones(len(y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, null_model)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the **residuals** of our model; that is, the actual values of our target vs the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(linreg.predict(X_train),y_train)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Predict the response for a new data point\n",
    "\n",
    "This is the exciting bit! New observations are called \"out-of-sample\" data. Our model uses the information it learned during the model training process.\n",
    "\n",
    "Let's ask the model to make two predictions:\n",
    "\n",
    "* One in a constituency where the youth population is 17%\n",
    "* Another where the youth population is 20%\n",
    "\n",
    "To do this, our feature matrix is always a 2-D array where each row is a list of features. Since we only have a single feature, the youth population, each row will contain only a single value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[17], [20]]\n",
    "linreg.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just predicted using our model is:\n",
    "\n",
    "* In a constituency where the proportion of 18-25 year olds is 17%, the X Party vote share will be around 32%\n",
    "* In a constituency where the proportion of 18-25 year olds is 20%, the X Party vote share will be around 38%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try: Linear regression to predict house sale price\n",
    "\n",
    "Now let's try this method out with a much bigger dataset! \n",
    "\n",
    "Read in the dataset, which describes house prices and other features collected from Boston and downloaded from Kaggle: https://www.kaggle.com/prasadperera/the-boston-housing-dataset\n",
    "\n",
    "Read the dictionary, which you can find here. Familiarise yourself with the features in the dataset:\n",
    "\n",
    "* CRIM - per capita crime rate by town\n",
    "* ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS - proportion of non-retail business acres per town.\n",
    "* CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "* NOX - nitric oxides concentration (parts per 10 million)\n",
    "* RM - average number of rooms per dwelling\n",
    "* AGE - proportion of owner-occupied units built prior to 1940\n",
    "* DIS - weighted distances to five Boston employment centres\n",
    "* RAD - index of accessibility to radial highways\n",
    "* TAX - full-value property-tax rate per 10,000USD\n",
    "* PTRATIO - pupil-teacher ratio by town\n",
    "* LSTAT - \\% lower status of the population\n",
    "* MEDV - Median value of owner-occupied homes in 1000USDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('boston_housing.csv')\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect missing values, and remove rows with `NaN` values using the ``dropna()`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 70% training, 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = \n",
    "y = \n",
    "X_train, X_test, y_train, y_test = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "\n",
    "Use `sns.pairplot`, `sns.heatmap`, `describe` and `corr` to:\n",
    "\n",
    "(a) Create a pairplot of some of the different pairings of variables in our dataset (this might take a while depending on how fast your laptop is!)\n",
    "\n",
    "(b) Generate a correlation matrix\n",
    "\n",
    "(c) Visualise the correlation matrix with a heatmap\n",
    "\n",
    "Then, by visual inspection, discuss the following questions on your tables:\n",
    "\n",
    "(a) Which variables look like they're most strongly associated or correlated with house price?\n",
    "\n",
    "(b) Do the associations make intuitive sense? If not, why not? \n",
    "\n",
    "(c) Do some of the associations look like they describe causal relationships? Which ones? \n",
    "\n",
    "(d) Which column is the target, or independent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fit a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise and fit a linear regression model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_regression = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the coefficient and intercept of the learned model, and plot the actual values of your dependent vs independent variable against the line of best fit, as in our dummy example above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the mean squared error of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = \n",
    "rmse = \n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a residual plot to assess the goodness of fit of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your linear model on out of sample data\n",
    "\n",
    "Now we've trained our simple linear model, we can read in our testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the accuracy of our model on unseen data, using root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = \n",
    "rmse = \n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the performance of the null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_null = \n",
    "\n",
    "mse =\n",
    "rmse = \n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the following questions:\n",
    "\n",
    "* Why is the testing accuracy of the model worse than the training accuracy?\n",
    "\n",
    "* Does our linear regression model perform better than the null model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='red'> Now you try: Linear regression to predict US presidential elections\n",
    "\n",
    "Read in the 2016 US Presidential dataset. Imagine you're trying to predict the Trump vote share in a county, using demographic information about that county.\n",
    "\n",
    "Follow the same steps as above to:\n",
    "\n",
    "* Perform an exploratory data analysis\n",
    "\n",
    "* Fit a linear regression model to predict Republican vote share in a county\n",
    "\n",
    "* Evaluate the model's performance on out-of-sample data\n",
    "\n",
    "* Compare the model's performance to a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
