{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Fundamentals\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "*After completing this notebook, you will be able to:*\n",
    "- Compute dot products, matrix multiplications, and vector norms by hand and using NumPy.\n",
    "- Code summary statistics using NumPy and Pandas: mean, median, mode, max, min, quartile, inter-quartile range, variance, standard deviation, and correlation.\n",
    "\n",
    "\n",
    "## Contents:\n",
    "* [Linear algebra review](#linear-algebra-review)\n",
    "* [Scalars, vectors and matrices](#scalars-vectors-and-matrices)\n",
    "* [Vector addition and subtraction](#vector-addition)\n",
    "* [Scalar multiplication](#scalar-multiplication)\n",
    "* [Dot product](#dot-product)\n",
    "* [Matrix multiplication](#matrix-multiplication)\n",
    "* [N-dimensional space](#n-dimensional-space)\n",
    "* [Vector norms](#vector-norms)\n",
    "* [Linear algebra in data science](#lin-alg-in-data-science)\n",
    "* [Our first model](#first-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "\n",
    "# <font color='blue'> Introduction\n",
    "\n",
    "Linear algebra is the branch of mathematics that deals with linear equations, including the use of vectors and matrices to solve linear problems in high dimensional space. \n",
    "\n",
    "Linear algebra is a need-to-know subject for machine learning. In fact, it forms the basis of foundational models such as linear regression, logistic regression, and principal component analysis (PCA). \n",
    "\n",
    "Unsurprisingly, advanced models such as neural networks and support vector machines rely on linear algebra as their \"trick\" for impressive speedups. Modern-day GPUs are essentially linear algebra supercomputers. And, to utilize their power on a GPU, models must often be carefully formulated in terms of vectors and matrices.\n",
    "\n",
    "More than that, today's advanced models build upon the simpler foundational models. Each neuron in a neural net is essentially a logistic regressor! Support vector machines utilize a kernel trick to craftily make problems linear that would not otherwise appear to be.\n",
    "\n",
    "Although we do not have time in this course to comprehensively discuss linear algebra, we highly recommend you become fluent!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# This makes sure that graphs render in your notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scalars-vectors-and-matrices\"></a>\n",
    "#  <font color='blue'> Scalars, Vectors and Matrices\n",
    "\n",
    "A **scalar** is a single number. Here, symbols that are lowercase single letters refer to scalars. For example, the symbols $a$ and $v$ are scalars that might refer to arbitrary numbers such as $5.328$ or $7$. An example scalar would be:\n",
    "\n",
    "$$a$$\n",
    "\n",
    "A **vector** is an ordered sequence of numbers. Here, symbols that are lowercase single letters with an arrow — such as $\\vec{u}$ — refer to vectors. An example vector would be:\n",
    "\n",
    "$$\\vec{u} = \\left[ \\begin{array}{c}\n",
    "1&3&7\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent vectors using numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([1, 3, 7])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An $m$ x $n$ **matrix** is a rectangular array of numbers with $m$ rows and $n$ columns. Each number in the matrix is an entry. Entries can be denoted $a_{ij}$, where $i$ denotes the row number and $j$ denotes the column number. Note that, because each entry $a_{ij}$ is a lowercase single letter, a matrix is an array of scalars:\n",
    "\n",
    "$$\\mathbf{A}= \\left[ \\begin{array}{c}\n",
    "a_{11} & a_{12} & ... & a_{1n}  \\\\\n",
    "a_{21} & a_{22} & ... & a_{2n}  \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{m1} & a_{m2} & ... & a_{mn}\n",
    "\\end{array} \\right]$$\n",
    "\n",
    "Matrices are referred to using bold uppercase letters, such as $\\mathbf{A}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1, 3, 7], [4, 6, 3], [2, 5, 6]])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in Python, a matrix is just a list of lists (or an array of arrays)! The outermost list is a list of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "\n",
    "You'll encounter $\\sum$ notation everywhere in machine learning and data science. The sum of a constant $k$, $n$ times\n",
    "$$\\sum_{i=1}^nk$$\n",
    "\n",
    "It is often helpful to think of these sums as `for` loops. For example, the equation can be compactly computed like so:\n",
    "\n",
    "```\n",
    "total = 0\n",
    "\n",
    "# For i from 1 up to and including n, add k to the sum.\n",
    "for i in range(1, n+1):\n",
    "    total += k\n",
    "```\n",
    "\n",
    "(a) Compute $\\sum_{i=1}^nk$ for $n=5$ and $k=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Compute $$\\sum_{i=1}^ni$$ for $n=5$, which is the sum of all numbers from 1 up to and including $n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Define a vector $x = [10,3,4,20,3]$ as a Numpy array and compute this for $n=3$, which is the sum of all $x$ from the first $x$ entry to the $n$th $x$ entry:\n",
    "$$\\sum_{i=0}^nx_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "    \n",
    "Here are three examples of sigma notation being used to calculate commonly used descriptive statistics.\n",
    "\n",
    "The mean — also known as the average or expected value — is defined as:\n",
    "$$E[X] = \\bar{X} =\\frac 1n\\sum_{i=1}^nx_i$$\n",
    "\n",
    "Standard deviation (SD, $σ$ for population standard deviation, or $s$ for sample standard deviation) is a measure that is used to quantify the amount of variation or dispersion from the mean of a set of data values. A low standard deviation means that most of the numbers are close to the average. A high standard deviation means that the numbers are spread out.\n",
    "\n",
    "Standard deviation is the square root of variance:\n",
    "\n",
    "$$variance = \\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$$\n",
    "\n",
    "$$s = \\sqrt{\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}}$$\n",
    "\n",
    "**Standard deviation** is often used because it is in the same units as the original data. Standard deviation is the only measure of dispersion or spread that it makes sense to visually draw alongside the original data.\n",
    "\n",
    "**Variance** is often used for efficiency in computations rather than the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Open the CSV file containing the Titanic dataset, from Kaggle: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "titanic = pd.read_csv('./data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Calculate the mean and median values of the ``fare`` column using built in Pandas methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) The mean and median are quite different. Does this tell you anything about the data? Can you verify this visually with a histogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Extract the first 5 rows of the ``age`` column of the titanic data by filling in the cell below. This is our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five = # fill this in!\n",
    "first_five = first_five.tolist()\n",
    "\n",
    "print(first_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What's $n$ in this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= # fill this in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Calculate $\\bar{X}$. Use basic python (**no** pandas or numpy) only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = # fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Calculate $\\sum{(x_i - \\bar{X})^2}$. Again, basic python (**no** pandas or numpy) only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_numerator = # fill this in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Now compute the variance, $variance = \\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) And finally, compute the standard deviation $s = \\sqrt{\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Now calculate the variance and the standard deviation using the pandas ``var`` and ``std`` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_series = titanic.loc[0:4,'age']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vector-addition\"></a>\n",
    "#  <font color='blue'> Vector addition and subtraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector **addition** is straightforward. If two vectors are of equal dimensions (The vectors are shown here as column vectors for convenience only):\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right],  \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\vec{v} + \\vec{w} =\n",
    "\\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] + \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "1+1 \\\\\n",
    "3+0 \\\\\n",
    "7+1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "8\n",
    "\\end{array} \\right]\n",
    "$\n",
    "\n",
    "(Subtraction is similar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v + w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scalar-multiplication\"></a>\n",
    "\n",
    "#  <font color='blue'> Scalar Multiplication\n",
    "    \n",
    "We scale a vector with **scalar multiplication**, multiplying a vector by a scalar (single quantity):\n",
    "\n",
    "$ 2 \\cdot \\vec{v} = 2\\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2 \\cdot 1 \\\\\n",
    "2 \\cdot 3 \\\\\n",
    "2 \\cdot 7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "6 \\\\\n",
    "14\n",
    "\\end{array} \\right]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * np.array([1, 3, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dot-product\"></a>\n",
    "#  <font color='blue'> Dot Product\n",
    "    \n",
    "The **dot product** of two _n_-dimensional vectors is:\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} =\\sum _{i=1}^{n}v_{i}w_{i}=v_{1}w_{1}+v_{2}w_{2}+\\cdots +v_{n}w_{n} $\n",
    "\n",
    "So, if:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right], \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} = 1 \\cdot 1 + 3 \\cdot 0 + 7 \\cdot 1 = 8 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])\n",
    "\n",
    "# Calculate the dot product of v and w using np.dot.\n",
    "v.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"matrix-multiplication\"></a>\n",
    "\n",
    "#  <font color='blue'>  Matrix Multiplication\n",
    "\n",
    "**Matrix multiplication**, $\\mathbf{A}_{mn}$ x $\\mathbf{B}_{ij}$, is valid when the left matrix has the same number of columns as the right matrix has rows ($n = i$). Each entry is the dot product of corresponding row and column vectors.\n",
    "\n",
    "![](./assets/images/matrix-multiply-a.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product illustrated above is: $1 \\cdot 7 + 2 \\cdot 9 + 3 \\cdot 11 = 58$. Can you compute the rest of the dot products by hand?\n",
    "\n",
    "If the product is the $2$ x $2$ matrix $\\mathbf{C}_{mj}$, then:\n",
    "\n",
    "+ Matrix entry $c_{12}$ (its FIRST row and SECOND column) is the dot product of the FIRST row of $\\mathbf{A}$ and the SECOND column of $\\mathbf{B}$.\n",
    "\n",
    "+ Matrix entry $c_{21}$ (its SECOND row and FIRST column) is the dot product of the SECOND row of $\\mathbf{A}$ and the FIRST column of $\\mathbf{B}$.\n",
    "\n",
    "Note that if the first matrix is $m$ x $n$ ($m$ rows and $n$ columns) and the second is  $i$ x $j$ (where $n = i$), then the final matrix will be $m$ x $j$. For example, below we have $2$ x $3$ multiplied by $3$ x $2$, which results in a $2$ x $2$ matrix. Can you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "A.dot(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you can compute this by hand!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "\n",
    "Calculate the following matrix and vector operations **by hand first** and then perform the same calculations using Numpy. \n",
    "\n",
    "\n",
    "$$\\vec{a} = \\left[ \\begin{array}{c}\n",
    "5 \\\\\n",
    "8 \\\\\n",
    "2\n",
    "\\end{array} \\right]\\:\\: \\:\\: \\vec{b} = \\left[ \\begin{array}{c}\n",
    "6 \\\\\n",
    "0 \\\\\n",
    "5\n",
    "\\end{array} \\right]\\:\\: \\:\\:\\mathbf{C}= \\left[ \\begin{array}{c}\n",
    "1 & 7 & 1 \\\\\n",
    "7 & 8 & 4\n",
    "\\end{array} \\right]\\:\\: \\:\\:\\mathbf{D}= \\left[ \\begin{array}{c}\n",
    "2 & 4 \\\\\n",
    "3 & 1 \\\\\n",
    "1 & 4\n",
    "\\end{array} \\right]$$\n",
    "\n",
    "(a) $a+b$\n",
    "\n",
    "(b) $a-b$\n",
    "\n",
    "(c) $3b$\n",
    "\n",
    "(d) $a \\cdot b$\n",
    "\n",
    "(e) $C \\times D$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"n-dimensional-space\"></a>\n",
    "\n",
    "#  <font color='blue'> N-Dimensional Space\n",
    "\n",
    "We often refer to vectors as elements of an $n$-dimensional space. \n",
    "\n",
    "The symbol $\\mathbb{R}$ refers to the set of all real numbers (written in uppercase \"blackboard bold\" font). \n",
    "\n",
    "A **real** number is a continuous value that can be represented on a number line. This includes **rational** numbers (any number that can be represented as a fraction) and **irrational** numbers like $\\sqrt{2}$. \n",
    "\n",
    "For example, $-1$, $3$ and $\\pi$ are real numbers, so we can say they are **contained in** $\\mathbb{R}$. \n",
    "\n",
    "We often write this symbolically as $3 \\in \\mathbb{R}$ and $\\pi \\in \\mathbb{R}$. \n",
    "\n",
    "To get the set of **all** pairs of real numbers, we would essentially take the product of this set with itself (called the Cartesian product) — $\\mathbb{R}$ x $\\mathbb{R}$, abbreviated as $\\mathbb{R}^2$. This set — $\\mathbb{R}^2$ — contains all pairs of real numbers, so $(1, 3)$ is **contained in** this set. We write this symbolically as $(1, 3) \\in \\mathbb{R}^2$.\n",
    "\n",
    "+ In 2-D space ($\\mathbb{R}^2$), a point is uniquely referred to using two coordinates: $(1, 3) \\in \\mathbb{R}^2$.\n",
    "+ In 3-D space ($\\mathbb{R}^3$), a point is uniquely referred to using three coordinates: $(8, 2, -3) \\in \\mathbb{R}^3$.\n",
    "+ In $n$-dimensional space ($\\mathbb{R}^n$), a point is uniquely referred to using $n$ coordinates.\n",
    "\n",
    "Note that these coordinates can be represented as vectors! \n",
    "\n",
    "After all, coordinates are ordered sequences of numbers, just as we define vectors to be ordered sequences of numbers. So, especially in machine learning, we often visualize vectors of length $n$ as points in $n$-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "\n",
    "(a) Draw a set of axes going from 0 to 5 on both the $x$ and $y$ axis\n",
    "\n",
    "(b) Draw the vector $\\vec{v} = \\left[ \\begin{array}{c}\n",
    "3 \\\\\n",
    "4 \n",
    "\\end{array} \\right]$ where the first element in the vector is the $x$ co-ordinate and the second is the $y$ co-ordinate\n",
    "\n",
    "(c) How can we calculate the length of this vector? Hint: think about Pythagoras!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vector-norms\"></a>\n",
    "\n",
    "#  <font color='blue'> Vector Norms\n",
    "\n",
    "The **magnitude** of a vector, $\\vec{v} \\in \\mathbb{R}^{n}$, can be interpreted as its length in $n$-dimensional space, or its distance from the origin.\n",
    "\n",
    "We've just calculated the magnitude of a 2D vector in the exercises above. For higher dimensional vectors, we take a similar approach. Vector magnitude is calculated using the Euclidean (or straight line) distance from the origin:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "v_{1} \\\\\n",
    "v_{2} \\\\\n",
    "\\vdots \\\\\n",
    "v_{n}\n",
    "\\end{array} \\right]$\n",
    "\n",
    "then $\\| \\vec{v} \\| = \\sqrt{v_{1}^{2} + v_{2}^{2} + ... + v_{n}^{2}} = \\sqrt{v^Tv}$\n",
    "\n",
    "E.g. if $\\vec{v} = \n",
    "\\left[ \\begin{array}{c}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{array} \\right]$, then $\\| \\vec{v} \\| = \\sqrt{3^{2} + 4^{2}} = 5$\n",
    "\n",
    "This is also called the vector **norm**. You will often see this used in machine learning. We can calculate this programmatically with Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3,4])\n",
    "\n",
    "# Calculate the norm of the vector x with np.linalg.norm.\n",
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "\n",
    "Given a vector $\\vec{y} = \\left[ \\begin{array}{c}\n",
    "3 \\\\\n",
    "4 \\\\\n",
    "5 \\\\\n",
    "1 \\\\\n",
    "2\n",
    "\\end{array} \\right]$\n",
    "\n",
    "(a) Calculate the vector magnitude by hand\n",
    "\n",
    "(b) Calculate the vector magnitude using Numpy and confirm the two answers are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lin-alg-in-data-science\"></a>\n",
    "\n",
    "#  <font color='blue'> Linear algebra in data science\n",
    "\n",
    "\n",
    "## Distance Between Actual Values and Predicted Values\n",
    "\n",
    "We often need to know the difference between predicted values and actual values. In 2-D space, we compute the difference or **distance** between two points or vectors as:\n",
    "\n",
    "$$\\| \\vec{actual} - \\vec{predicted} \\| =\\sqrt{(actual_1 - predicted_1)^2 + (actual_2 - predicted_2)^2}$$\n",
    "\n",
    "\n",
    "Often, it's easier to look at the mean of the squared errors. Where $\\hat{y}(\\mathbf{X})$ is a vector of predicted values (a function of the data matrix $\\mathbf{X}$) and $\\vec{y}$ is the actual values:\n",
    "\n",
    "$$MSE = \\frac{1} {n} \\| \\hat{y}(\\mathbf{X}) - \\vec{y} \\|^2$$\n",
    "\n",
    "\n",
    "Many machine learning models are based on minimising the mean squared error between predicted and actual values during the training process. This goal is written in the following form:\n",
    "\n",
    "$$\\min \\| \\hat{y}(\\mathbf{X}) - \\vec{y} \\|$$\n",
    "\n",
    "When we discuss error, it's often helpful for the size of the error to be in the same units as the target variable. Here, we use RMSE or **root** mean squared error. \n",
    "\n",
    "$$\\sqrt{\\min \\| \\hat{y}(\\mathbf{X}) - \\vec{y} \\|}$$\n",
    "\n",
    "## <font color='red'> Now you try\n",
    "\n",
    "Imagine we've built a model to predict the percentage vote share, in each constituency, for the main opposition party in the next general election. Let's say that for five constituencies, our model predicts the opposition vote share as $\\hat{y} = \\left[\n",
    "55,\n",
    "48,\n",
    "39,\n",
    "49,\n",
    "76\n",
    "\\right]$\n",
    "\n",
    "Let's assume the actual opposition vote shares in those constituencies turn out to be $y = \\left[\n",
    "50,\n",
    "47,\n",
    "39,\n",
    "52,\n",
    "77\n",
    " \\right]$\n",
    "\n",
    "(a) Referring to the definition of mean squared error above, what's the value of $n$ in this example?\n",
    "\n",
    "(b) Calculate the magnitude, or vector norm, of $\\hat{y}$\n",
    "\n",
    "(b) Calculate the mean squared error by hand\n",
    "\n",
    "(c) Fill in the gaps in the code cell below to calculate the mean squared error using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_predicted = # fill this in!\n",
    "y_actual = # fill this in too\n",
    "\n",
    "mean_squared_error(y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"first-model\"></a>\n",
    "\n",
    "#  <font color='blue'> Our first model\n",
    "\n",
    "Remember that model is a way of capturing or representing a real world process or problem in a simplified, mathematical way. When we ask data science questions like:\n",
    "\n",
    "What's the relationship between $x$ and $y$?\n",
    "\n",
    "Does $x$ predict $y$?\n",
    "\n",
    "**We're actually asking questions like**\n",
    "\n",
    "Can we model the relationship between $x$ and $y$?\n",
    "\n",
    "Can we model $y$ as a function of $x$?\n",
    "\n",
    "## Features and targets\n",
    "\n",
    "Let's say we want to predict the price of a house. In mathematical terms, house price is our **dependent variable** or the quantity we're trying to predict. In machine learning terminology, this is often called the **label** or **target**. \n",
    "\n",
    "The next step would be to select some other sources of information that we think we could use to predict the price of a house. Those other pieces of information might be:\n",
    "\n",
    "* Number of bedrooms\n",
    "* Number of bathrooms\n",
    "* Average income on the street\n",
    "\n",
    "These are our **independent variables** or **features**. \n",
    "\n",
    "Next, we formulate our data science question. In this case, it would be either:\n",
    "\n",
    "**What's the relationship between house price and number of bedrooms, number of bathrooms, and average income on the street?**\n",
    "\n",
    "or\n",
    "\n",
    "**How well do number of bedrooms, number of bathrooms, and average street income predict the price of a house?**\n",
    "\n",
    "## <font color='red'> Now you try\n",
    "\n",
    "Imagine we're trying to predict a university student's degree class (First, Upper Second Class, Lower Second Class, or Third Class) using:\n",
    "\n",
    "* Litres of coffee consumed by the student in their final year\n",
    "* The number of A grades achieved by the student at A-Level\n",
    "* The student's percentage attendance at lectures\n",
    "\n",
    "(a) Identify the independent and dependent variables\n",
    "\n",
    "(b) Is the dependent variable categorical or continuous?\n",
    "\n",
    "(c) Are each of the independent variables categorical or continuous?\n",
    "\n",
    "---\n",
    "\n",
    "Now imagine you're trying to predict whether a borrower will default on a mortgage repayment. \n",
    "\n",
    "(a) What's the dependent variable? \n",
    "\n",
    "(b) Is the dependent variable categorical or continuous?\n",
    "\n",
    "(c) Name five features that you might use to predict the dependent variable\n",
    "\n",
    "(d) Are the features categorical or continuous? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an extremely simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our first model from scratch. We'll use our model predict the `fare` column in the Titanic data. So which features will we use? Actually, none.\n",
    "\n",
    "The absolute simplest model we can build doesn't involve any features at all!\n",
    "\n",
    "We can model our target using a single, constant value. This can be represented as:\n",
    "\n",
    "$$y = a_0$$\n",
    "\n",
    "Where our target, $y$ is predicted using the constant $a_0$.\n",
    "\n",
    "We can use the mean, median, or mode of our independent variable as a very simple model. If we have no feature matrix and only an outcome, this is the best approach to make a prediction using only empirical data. \n",
    "\n",
    "This seems silly, but we'll actually use it all the time to create a baseline of how well we do with no data and determine whether or not our more sophisticated models make an improvement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Now you try\n",
    "\n",
    "Let's try it out by trying to predict Titanic ticket prices using no features at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Extract the `fare` column from the Titanic data and store it as the variable `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = # fill this in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Create a variable `y_pred` using the mean of `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = # fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Find the mean squared error of your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Mean squared error is hard to read! Calculate the root mean squared error (RMSE), the square root of the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
